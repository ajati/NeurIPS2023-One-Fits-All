train 544095
val 814377
test 1657965
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
Model params that has gradient
gpt2.wpe.weight: requires_grad=True : #params=786432
gpt2.h.0.ln_1.weight: requires_grad=True : #params=768
gpt2.h.0.ln_1.bias: requires_grad=True : #params=768
gpt2.h.0.ln_2.weight: requires_grad=True : #params=768
gpt2.h.0.ln_2.bias: requires_grad=True : #params=768
gpt2.h.1.ln_1.weight: requires_grad=True : #params=768
gpt2.h.1.ln_1.bias: requires_grad=True : #params=768
gpt2.h.1.ln_2.weight: requires_grad=True : #params=768
gpt2.h.1.ln_2.bias: requires_grad=True : #params=768
gpt2.h.2.ln_1.weight: requires_grad=True : #params=768
gpt2.h.2.ln_1.bias: requires_grad=True : #params=768
gpt2.h.2.ln_2.weight: requires_grad=True : #params=768
gpt2.h.2.ln_2.bias: requires_grad=True : #params=768
gpt2.h.3.ln_1.weight: requires_grad=True : #params=768
gpt2.h.3.ln_1.bias: requires_grad=True : #params=768
gpt2.h.3.ln_2.weight: requires_grad=True : #params=768
gpt2.h.3.ln_2.bias: requires_grad=True : #params=768
gpt2.h.4.ln_1.weight: requires_grad=True : #params=768
gpt2.h.4.ln_1.bias: requires_grad=True : #params=768
gpt2.h.4.ln_2.weight: requires_grad=True : #params=768
gpt2.h.4.ln_2.bias: requires_grad=True : #params=768
gpt2.h.5.ln_1.weight: requires_grad=True : #params=768
gpt2.h.5.ln_1.bias: requires_grad=True : #params=768
gpt2.h.5.ln_2.weight: requires_grad=True : #params=768
gpt2.h.5.ln_2.bias: requires_grad=True : #params=768
gpt2.ln_f.weight: requires_grad=True : #params=768
gpt2.ln_f.bias: requires_grad=True : #params=768
in_layer.weight: requires_grad=True : #params=12288
in_layer.bias: requires_grad=True : #params=768
out_layer.weight: requires_grad=True : #params=2433024
out_layer.bias: requires_grad=True : #params=96
Total #params manual = 3252576
VJ: total learnable params:  3252576
VJ: total params:  84358752
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
flops calculation failed CUDA out of memory. Tried to allocate 3.88 GiB (GPU 0; 39.39 GiB total capacity; 33.40 GiB already allocated; 1.85 GiB free; 36.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
-------------------------------------------------- MACs across 10% train data = None nparams = None
self vs thop trainable params 3252576 None
0it [00:00, ?it/s]0it [00:00, ?it/s]
Traceback (most recent call last):
  File "/dccstor/tsfm-irl/vijaye12/opensource/NeurIPS2023-One-Fits-All/Few-shot_Learning/main.py", line 263, in <module>
    outputs = model(batch_x, ii)
  File "/dccstor/tsfm-irl/conda_envs/envs/tsfmvj/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dccstor/tsfm-irl/vijaye12/opensource/NeurIPS2023-One-Fits-All/Few-shot_Learning/models/GPT4TS.py", line 70, in forward
    outputs = self.gpt2(inputs_embeds=outputs).last_hidden_state
  File "/dccstor/tsfm-irl/conda_envs/envs/tsfmvj/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dccstor/tsfm-irl/conda_envs/envs/tsfmvj/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 900, in forward
    outputs = block(
  File "/dccstor/tsfm-irl/conda_envs/envs/tsfmvj/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dccstor/tsfm-irl/conda_envs/envs/tsfmvj/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 427, in forward
    feed_forward_hidden_states = self.mlp(hidden_states)
  File "/dccstor/tsfm-irl/conda_envs/envs/tsfmvj/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dccstor/tsfm-irl/conda_envs/envs/tsfmvj/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 354, in forward
    hidden_states = self.c_fc(hidden_states)
  File "/dccstor/tsfm-irl/conda_envs/envs/tsfmvj/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dccstor/tsfm-irl/conda_envs/envs/tsfmvj/lib/python3.9/site-packages/transformers/pytorch_utils.py", line 106, in forward
    x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)
RuntimeError: CUDA out of memory. Tried to allocate 3.88 GiB (GPU 0; 39.39 GiB total capacity; 35.43 GiB already allocated; 917.94 MiB free; 37.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

------------------------------------------------------------
Sender: LSF System <lsfadmin@cccxc529.pok.ibm.com>
Subject: Job 954378: <sh /dccstor/tsfm-irl/vijaye12/opensource/NeurIPS2023-One-Fits-All/Few-shot_Learning/scripts/electricity_complexity_vj.sh> in cluster <cccCluster> Done

Job <sh /dccstor/tsfm-irl/vijaye12/opensource/NeurIPS2023-One-Fits-All/Few-shot_Learning/scripts/electricity_complexity_vj.sh> was submitted from host <cccxl012.pok.ibm.com> by user <vijaye12> in cluster <cccCluster> at Mon Dec 25 05:36:00 2023
Job was executed on host(s) <32*cccxc529.pok.ibm.com>, in queue <platform>, as user <vijaye12> in cluster <cccCluster> at Mon Dec 25 05:36:00 2023
</u/vijaye12> was used as the home directory.
</dccstor/tsfm-irl/vijaye12/opensource/NeurIPS2023-One-Fits-All/Few-shot_Learning> was used as the working directory.
Started at Mon Dec 25 05:36:00 2023
Terminated at Mon Dec 25 05:36:18 2023
Results reported at Mon Dec 25 05:36:18 2023

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
sh /dccstor/tsfm-irl/vijaye12/opensource/NeurIPS2023-One-Fits-All/Few-shot_Learning/scripts/electricity_complexity_vj.sh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   112.66 sec.
    Max Memory :                                 2568 MB
    Average Memory :                             1742.20 MB
    Total Requested Memory :                     450560.00 MB
    Delta Memory :                               447992.00 MB
    Max Swap :                                   -
    Max Processes :                              13
    Max Threads :                                102
    Run time :                                   16 sec.
    Turnaround time :                            18 sec.

The output (if any) is above this job summary.



PS:

Read file <./err.txt> for stderr output of this job.

